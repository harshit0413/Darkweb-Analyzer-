{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshit0413/Darkweb-Analyzer-/blob/main/Darkweb-Analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1Z6nuwrvzLN",
        "outputId": "2de670f1-f828-4b9a-d82a-a2d999feba38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.2)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n"
          ]
        }
      ],
      "source": [
        "pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scapy"
      ],
      "metadata": {
        "id": "Hbo0GRtQwCpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7d1116-f416-47d7-c547-c2b2279d73ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scapy in /usr/local/lib/python3.10/dist-packages (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# Load the labeled dataset\n",
        "df_labeled = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/csv/darknet-normal.csv')\n",
        "\n",
        "df_labeled.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "df_labeled.fillna(0, inplace=True)  # or\n",
        "\n",
        "# Define the features to keep, based on the extract_features function\n",
        "features_to_keep = [\n",
        "    'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets',\n",
        "    'Packet Length Min', 'Packet Length Mean', 'Fwd IAT Total',\n",
        "    'Flow IAT Min', 'Flow IAT Max', 'Fwd IAT Mean', 'Flow Packets/s',\n",
        "    'Flow Bytes/s', 'Idle Min', 'Idle Max', 'Idle Mean',\n",
        "    'Idle Std', 'FWD Init Win Bytes', 'Bwd Init Win Bytes', 'ACK Flag Count'\n",
        "]\n",
        "\n",
        "# Keep only the relevant features\n",
        "df_relevant_features = df_labeled[features_to_keep + ['Label']]\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df_relevant_features.drop('Label', axis=1)\n",
        "\n",
        "y = df_relevant_features['Label'].map({'Normal': 'normal', 'FreeNet': 'darknet', 'I2P': 'darknet', 'Tor': 'darknet', 'ZeroNet': 'darknet'})\n",
        "\n",
        "df_labeled.fillna(0, inplace=True)\n",
        "\n",
        "# Split into training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply one-hot encoding only to the train dataset to avoid memory issues\n",
        "X_train = pd.get_dummies(X_train, drop_first=True)\n",
        "X_test = pd.get_dummies(X_test, drop_first=True)\n",
        "\n",
        "# Align X_train and X_test to ensure they have the same columns\n",
        "X_train, X_test = X_train.align(X_test, join='inner', axis=1)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "Xgb_classify = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, seed=42)\n",
        "\n",
        "# Encode the labels with LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Train the classifier with the encoded binary labels\n",
        "Xgb_classify.fit(X_train,y_train_encoded)\n",
        "\n",
        "# Make predictions with the encoded labels\n",
        "encoded_predictions = Xgb_classify.predict(X_test)\n",
        "\n",
        "# Decode the predictions back to original labels\n",
        "predictions = label_encoder.inverse_transform(encoded_predictions)\n",
        "accuracy = accuracy_score(y_test_encoded, encoded_predictions)\n",
        "precision = precision_score(y_test_encoded, encoded_predictions, pos_label=label_encoder.transform(['darknet'])[0])\n",
        "recall = recall_score(y_test_encoded, encoded_predictions, pos_label=label_encoder.transform(['darknet'])[0])\n",
        "f1 = f1_score(y_test_encoded, encoded_predictions, pos_label=label_encoder.transform(['darknet'])[0])\n",
        "\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')\n"
      ],
      "metadata": {
        "id": "WauJC2gfzwbL",
        "outputId": "002ad982-f239-4ebb-9624-e259a6cf6c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9944990484135882\n",
            "Precision: 0.9959913326110509\n",
            "Recall: 0.9926037898828484\n",
            "F1 Score: 0.9942946759321851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the model\n",
        "Xgb_classify.save_model('xgb_model.json')"
      ],
      "metadata": {
        "id": "EswxTM2fiJtL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the model\n",
        "loaded_model = xgb.XGBClassifier()\n",
        "loaded_model.load_model('xgb_model.json')"
      ],
      "metadata": {
        "id": "g0f8X2n3izct"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scapy.all import rdpcap, IP, TCP\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def extract_features(pcap_file):\n",
        "    packets = rdpcap(pcap_file)\n",
        "    features = {\n",
        "        'Flow Duration': 0.0,\n",
        "        'Total Fwd Packet': 0,\n",
        "        'Total Bwd packets': 0,\n",
        "        'Packet Length Min': np.inf,\n",
        "        'Packet Length Mean': 0.0,\n",
        "        'Fwd IAT Total': 0.0,\n",
        "        'Flow IAT Min': np.inf,\n",
        "        'Flow IAT Max': 0.0,\n",
        "        'Fwd IAT Mean': 0.0,\n",
        "        'Flow Packets/s': 0.0,\n",
        "        'Flow Bytes/s': 0.0,\n",
        "        'Idle Min': np.inf,\n",
        "        'Idle Max': 0.0,\n",
        "        'Idle Mean': 0.0,\n",
        "        'Idle Std': 0.0,\n",
        "        'FWD Init Win Bytes': 0,\n",
        "        'Bwd Init Win Bytes': 0,\n",
        "        'ACK Flag Count': 0\n",
        "    }\n",
        "\n",
        "    if not packets:\n",
        "        return pd.DataFrame(features, index=[0])\n",
        "\n",
        "    start_times = []\n",
        "    packet_lengths = []\n",
        "    iats = []\n",
        "    total_bytes = 0\n",
        "\n",
        "    for packet in packets:\n",
        "        if IP in packet and TCP in packet:\n",
        "            packet_length = len(packet)\n",
        "            packet_lengths.append(packet_length)\n",
        "            total_bytes += packet_length\n",
        "\n",
        "            if 'S' in packet[TCP].flags:\n",
        "                if features['FWD Init Win Bytes'] == 0:\n",
        "                    features['FWD Init Win Bytes'] = packet[TCP].window\n",
        "                else:\n",
        "                    features['Bwd Init Win Bytes'] = packet[TCP].window\n",
        "\n",
        "            if 'A' in packet[TCP].flags:\n",
        "                features['ACK Flag Count'] += 1\n",
        "\n",
        "            start_times.append(float(packet.time))\n",
        "\n",
        "            if len(start_times) > 1:\n",
        "                iat = start_times[-1] - start_times[-2]\n",
        "                iats.append(iat)\n",
        "\n",
        "    features['Flow Duration'] = max(start_times) - min(start_times)\n",
        "    features['Total Fwd Packet'] = len([p for p in packets if IP in p and p[IP].src < p[IP].dst])\n",
        "    features['Total Bwd packets'] = len([p for p in packets if IP in p and p[IP].src > p[IP].dst])\n",
        "    features['Packet Length Min'] = min(packet_lengths)\n",
        "    features['Packet Length Mean'] = np.mean(packet_lengths) if packet_lengths else 0\n",
        "    features['Fwd IAT Total'] = sum(iats)\n",
        "    features['Flow IAT Min'] = min(iats) if iats else 0\n",
        "    features['Flow IAT Max'] = max(iats) if iats else 0\n",
        "    features['Flow IAT Min'] = np.mean(iats) if iats else 0\n",
        "    features['Flow Packets/s'] = len(packets) / features['Flow Duration'] if features['Flow Duration'] else 0\n",
        "    features['Flow Bytes/s'] = total_bytes / features['Flow Duration'] if features['Flow Duration'] else 0\n",
        "\n",
        "    # Handle potential NaNs and infs\n",
        "    for key, value in features.items():\n",
        "        if isinstance(value, float) and (np.isinf(value) or np.isnan(value)):\n",
        "            features[key] = 0\n",
        "\n",
        "    df_features = pd.DataFrame([features])\n",
        "\n",
        "# Handle potential NaNs and infs again before returning\n",
        "    df_features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df_features.fillna(0, inplace=True)\n",
        "\n",
        "    return df_features\n"
      ],
      "metadata": {
        "id": "IOyaNRLmpDMj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "def classify_traffic(df_features, model_path):\n",
        "    # Load the trained model\n",
        "    xgb_model = xgb.XGBClassifier()\n",
        "\n",
        "    # Load the model\n",
        "    xgb_model.load_model(model_path)\n",
        "\n",
        "    # Ensure that the model has been fitted before making predictions\n",
        "    if not xgb_model.get_booster().attr(\"n_features\"):\n",
        "        raise ValueError(\"Model needs to be fitted before making predictions\")\n",
        "\n",
        "    # Predict the traffic class\n",
        "    predictions = xgb_model.predict(df_features)\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "13BCBos7s1Vz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "model_path = '/content/xgb_model.json'  # Make sure this is the correct path to your model file\n",
        "pcap_file_path = '/content/drive/MyDrive/Colab Notebooks/pcap/zeronet-p2p_00001_20200421125502.pcap'\n",
        "\n",
        "# Loading the trained XGBoost model\n",
        "xgb_classifier = xgb.XGBClassifier()\n",
        "xgb_classifier.load_model(model_path)\n",
        "\n",
        "# Extract features from the pcap file\n",
        "df_features = extract_features(pcap_file_path)\n",
        "\n",
        "# Output the predicted class\n",
        "print(\"Predicted Class:\", predictions[0])\n",
        "print(label_encoder.classes_)"
      ],
      "metadata": {
        "id": "yjaOYMf-yUa2",
        "outputId": "4095042a-72ba-4639-f38f-53e24603741e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 0\n",
            "['darknet' 'normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if isinstance(df_features, pd.Series):\n",
        "    df_features = df_features.to_frame().transpose()\n",
        "\n",
        "predictions = xgb_classifier.predict(df_features)"
      ],
      "metadata": {
        "id": "Y8FgKgdl_Lqj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if predictions[0] == 0:\n",
        "    print(\"Darknet\")\n",
        "else:\n",
        "    print(\"Normal\")"
      ],
      "metadata": {
        "id": "F1fFX3Zx_QXj",
        "outputId": "cbb908c0-7ed1-45d5-bfc9-b26a41d0c79f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Darknet\n"
          ]
        }
      ]
    }
  ]
}